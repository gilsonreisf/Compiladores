{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabela_de_estados import TabelaDeEstados\n",
    "from Tabela_de_Simbolos import Tabela_de_Simbolos\n",
    "from Token import Token\n",
    "\n",
    "class Scanner:\n",
    "  def __init__(self):\n",
    "    self.numero_da_coluna = 0\n",
    "    self.numero_da_linha = 0\n",
    "    self.lexema = ''\n",
    "    self.arrayParaIdentificarColuna = []\n",
    "\n",
    "\n",
    "  def scanner(self, tabelaEstados: TabelaDeEstados, arrayDeCaracteres: str, tabelaDeSimbolos: Tabela_de_Simbolos):\n",
    "    char = arrayDeCaracteres\n",
    "    entrada = tabelaEstados.verificaTipoCaractere(char).strip()\n",
    "    if(entrada == '$'):\n",
    "      return {'mensagem': 'EOF', 'token': Token(classe='EOF', lexema='EOF',tipo='EOF')}\n",
    "    if (tabelaEstados.verificarSeEntradaPertenceAoAlfabeto(entrada)):\n",
    "      if(tabelaEstados.verificarSeProximoEstadoEValido(entrada)):\n",
    "        self.lexema = self.lexema + char.strip()\n",
    "        return {'mensagem': 'chamar_novamente', 'token': None}\n",
    "      elif(tabelaEstados.verificarSeEFinalDefinitivo(entrada)):\n",
    "          newToken = Token(tabelaEstados.retornaClasse(), self.lexema, tabelaEstados.retornaTipo())\n",
    "          return {'mensagem': 'TOKEN_DIRETO', 'token': newToken}\n",
    "      elif (tabelaEstados.verificarSeEstaEmEstadoFinal()):\n",
    "        newToken = Token(tabelaEstados.retornaClasse(), self.lexema, tabelaEstados.retornaTipo())\n",
    "        return {'mensagem': 'TOKEN', 'token': newToken}\n",
    "      else:\n",
    "        tabelaEstados.lancarErro(self.numero_da_linha, self.numero_da_coluna)\n",
    "        return {'mensagem': None, 'token': 'ERRO'}\n",
    "    elif(tabelaEstados.entradaVazia(char)):\n",
    "      if (tabelaEstados.verificarSeEstaEmEstadoFinal()):\n",
    "        newToken = Token(tabelaEstados.retornaClasse(), self.lexema, tabelaEstados.retornaTipo())\n",
    "        return {'mensagem': 'TOKEN', 'token': newToken}\n",
    "      elif(tabelaEstados.verificarSeComentarioOuLiteral()):\n",
    "        return {'mensagem': 'tratar_literal_comentario', 'token': None}\n",
    "      else:\n",
    "        return {'mensagem': 'chamar_novamente', 'token': None}\n",
    "    elif(tabelaEstados.verificarSeComentarioOuLiteral()):\n",
    "        return {'mensagem': 'tratar_literal_comentario', 'token': None}\n",
    "    else:\n",
    "      self.numero_da_coluna = self.arrayParaIdentificarColuna.index(char) + 1\n",
    "      print('ERRO LÉXICO – Caracter inválido, linha {}, coluna {}'.format(self.numero_da_linha, self.numero_da_coluna))\n",
    "      return {'mensagem': None, 'token': 'ERRO'}\n",
    "\n",
    "\n",
    "\n",
    "  def tratarFinalDaInstrucao(self, tabelaEstados: TabelaDeEstados, jaLancouErro = False):\n",
    "    if (tabelaEstados.verificarSeEstaEmEstadoFinal()):\n",
    "      newToken = Token(tabelaEstados.retornaClasse(), self.lexema, tabelaEstados.retornaTipo())\n",
    "      return {'mensagem': 'TOKEN', 'token': newToken}\n",
    "    else:\n",
    "      if(jaLancouErro == False):\n",
    "        tabelaEstados.lancarErro(self.numero_da_linha, self.numero_da_coluna)\n",
    "      self.lexema = ''\n",
    "      return {'mensagem': None, 'token': 'ERRO'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def limpa_codigo(self, codigoFonteFormatado):\n",
    "    codigo_final = []\n",
    "    for line in codigoFonteFormatado:\n",
    "        for caractere in line:\n",
    "            codigo_final.append(caractere)\n",
    "    return codigo_final\n",
    "\n",
    "  def scannerMain(self, tabelaEstados: TabelaDeEstados, codigoFonte, tabelaDeSimbolos: Tabela_de_Simbolos):\n",
    "    for linha in codigoFonte:\n",
    "\n",
    "      arrayDeCaracteres = self.limpa_codigo(linha)\n",
    "      self.arrayParaIdentificarColuna = arrayDeCaracteres.copy()\n",
    "\n",
    "      self.numero_da_linha += 1\n",
    "      print('---------------------------------- LINHA {} ----------------------------------'.format(self.numero_da_linha))\n",
    "      coluna = 0\n",
    "      retorno = self.scanner(tabelaEstados, arrayDeCaracteres[0].replace(\" \", \"\"), tabelaDeSimbolos)\n",
    "      arrayDeCaracteres.pop(0)\n",
    "\n",
    "      if(retorno['mensagem'] == 'EOF'):\n",
    "        print('TOKEN - Classe: EOF, Lexema: EOF, Tipo: EOF')\n",
    "        return # Final do arquivo\n",
    "      while(retorno['mensagem'] != 'EOF' and len(arrayDeCaracteres) != 0):\n",
    "        if(retorno['mensagem'] == 'chamar_novamente'):\n",
    "          coluna += 1\n",
    "          retorno = self.scanner(tabelaEstados, arrayDeCaracteres[0].replace(\" \", \"\"), tabelaDeSimbolos)\n",
    "          if(retorno['mensagem'] != 'TOKEN' and retorno['mensagem'] != 'TOKEN_DIRETO'):\n",
    "            arrayDeCaracteres.pop(0)\n",
    "          continue\n",
    "        elif(retorno['mensagem'] == 'TOKEN'):\n",
    "          tokenTabela = tabelaDeSimbolos.construir_token(tabelaEstados, retorno['token'].lexema)\n",
    "          print('TOKEN - Classe: {}, Lexema: {}, Tipo: {}'.format(tokenTabela.classe, tokenTabela.lexema, tokenTabela.tipo))\n",
    "          tabelaEstados.estado_atual = 0\n",
    "          self.lexema = ''\n",
    "          retorno = self.scanner(tabelaEstados, arrayDeCaracteres[0].replace(\" \", \"\"), tabelaDeSimbolos)\n",
    "          arrayDeCaracteres.pop(0)\n",
    "          continue\n",
    "        elif(retorno['mensagem'] == 'TOKEN_DIRETO'):\n",
    "          tokenTabela = tabelaDeSimbolos.construir_token(tabelaEstados, retorno['token'].lexema)\n",
    "          print('TOKEN - Classe: {}, Lexema: {}, Tipo: {}'.format(tokenTabela.classe, tokenTabela.lexema, tokenTabela.tipo))\n",
    "\n",
    "          tabelaEstados.estado_atual = 0\n",
    "          arrayDeCaracteres.pop(0)\n",
    "          self.lexema = ''\n",
    "          \n",
    "          retorno = self.scanner(tabelaEstados, arrayDeCaracteres[0].replace(\" \", \"\"), tabelaDeSimbolos)\n",
    "          continue\n",
    "        elif(retorno['mensagem']  == None): #Espaço vazio\n",
    "          jaLancouErro = retorno['token'] == 'ERRO'\n",
    "          ultimoTokenAntesDoErro = self.tratarFinalDaInstrucao(tabelaEstados, jaLancouErro)\n",
    "          if(ultimoTokenAntesDoErro['mensagem'] == 'TOKEN'):\n",
    "            tokenTabela = tabelaDeSimbolos.construir_token(tabelaEstados, ultimoTokenAntesDoErro['token'].lexema)\n",
    "            print('TOKEN - Classe: {}, Lexema: {}, Tipo: {}'.format(tokenTabela.classe, tokenTabela.lexema, tokenTabela.tipo))\n",
    "          \n",
    "          tabelaEstados.estado_atual = 0\n",
    "          self.lexema = ''\n",
    "          retorno['mensagem'] = 'chamar_novamente'\n",
    "          coluna += 1\n",
    "          continue\n",
    "\n",
    "        elif(retorno['mensagem']  == 'tratar_literal_comentario'):\n",
    "          self.lexema =  self.lexema + ' '\n",
    "          retorno['mensagem'] = 'chamar_novamente'\n",
    "          continue\n",
    "\n",
    "\n",
    "      jaLancouErro = retorno['token'] == 'ERRO'\n",
    "      ultimoTokenDaLinha = self.tratarFinalDaInstrucao(tabelaEstados, jaLancouErro)\n",
    "      if(ultimoTokenDaLinha['mensagem'] == 'TOKEN'):\n",
    "        tokenTabela = tabelaDeSimbolos.construir_token(tabelaEstados, ultimoTokenDaLinha['token'].lexema)\n",
    "        print('TOKEN - Classe: {}, Lexema: {}, Tipo: {}'.format(tokenTabela.classe, tokenTabela.lexema, tokenTabela.tipo))\n",
    "        tabelaEstados.estado_atual = 0\n",
    "        self.lexema = ''\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inicio',\n",
       " 'varinicio',\n",
       " 'literal A;',\n",
       " 'inteiro B, D, E;',\n",
       " 'real C ;',\n",
       " 'varfim;',\n",
       " 'escreva \"Digite B:\";',\n",
       " 'leia B;',\n",
       " 'escreva \"Digite A:\";',\n",
       " 'leia A;',\n",
       " 'se(B>2)',\n",
       " 'entao',\n",
       " 'se(B<=4)',\n",
       " 'entao',\n",
       " 'escreva \"B esta entre 2 e 4\";',\n",
       " 'fimse',\n",
       " 'fimse',\n",
       " 'B<-B+1;',\n",
       " 'B<-B+2;',\n",
       " 'B<-B+3;',\n",
       " 'D<-B;',\n",
       " 'C<-5.0;',\n",
       " 'E<-B+2;',\n",
       " 'escreva C;',\n",
       " 'B<-B+1;',\n",
       " 'escreva \"\\nB=\\n; { \\n e o simbolo para salto de linha}',\n",
       " 'escreva D;',\n",
       " 'escreva \"\\n\";',\n",
       " 'escreva C;',\n",
       " 'escreva \"\\n\";',\n",
       " 'escreva A;',\n",
       " 'fim',\n",
       " '$']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivo = open(\"teste.txt\", \"r+\", encoding=\"utf-8\")\n",
    "codigoFonte = arquivo.readlines()\n",
    "\n",
    "def limpa_codigo(codigoFonte):\n",
    "  novo_codigo = []\n",
    "  ultimo_elemento = codigoFonte[-1]\n",
    "  for i in codigoFonte:\n",
    "    if(i.strip() == ultimo_elemento.strip()):\n",
    "      i = i + '\\n'\n",
    "    nova_string = bytes(i, \"utf-8\").decode(\"unicode_escape\")\n",
    "    novo_codigo.append(nova_string[:][:-1])\n",
    "  novo_codigo.append('$')\n",
    "  return novo_codigo\n",
    "  \n",
    "codigoFormatado = limpa_codigo(codigoFonte)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "codigoFormatado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------- LINHA 1 ----------------------------------\n",
      "TOKEN - Classe: inicio, Lexema: inicio, Tipo: inicio\n",
      "---------------------------------- LINHA 2 ----------------------------------\n",
      "TOKEN - Classe: varinicio, Lexema: varinicio, Tipo: varinicio\n",
      "---------------------------------- LINHA 3 ----------------------------------\n",
      "TOKEN - Classe: literal, Lexema: literal, Tipo: literal\n",
      "TOKEN - Classe: id, Lexema: A, Tipo: NULO\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 4 ----------------------------------\n",
      "TOKEN - Classe: inteiro, Lexema: inteiro, Tipo: inteiro\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: VIR, Lexema: ,, Tipo: NULO\n",
      "TOKEN - Classe: id, Lexema: D, Tipo: NULO\n",
      "TOKEN - Classe: VIR, Lexema: ,, Tipo: NULO\n",
      "TOKEN - Classe: id, Lexema: E, Tipo: NULO\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 5 ----------------------------------\n",
      "TOKEN - Classe: real, Lexema: real, Tipo: real\n",
      "TOKEN - Classe: id, Lexema: C, Tipo: NULO\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 6 ----------------------------------\n",
      "TOKEN - Classe: varfim, Lexema: varfim, Tipo: varfim\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 7 ----------------------------------\n",
      "TOKEN - Classe: escreva, Lexema: escreva, Tipo: escreva\n",
      "TOKEN - Classe: Lit, Lexema: \"Digite B:\", Tipo: literal\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 8 ----------------------------------\n",
      "TOKEN - Classe: leia, Lexema: leia, Tipo: leia\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 9 ----------------------------------\n",
      "TOKEN - Classe: escreva, Lexema: escreva, Tipo: escreva\n",
      "TOKEN - Classe: Lit, Lexema: \"Digite A:\", Tipo: literal\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 10 ----------------------------------\n",
      "TOKEN - Classe: leia, Lexema: leia, Tipo: leia\n",
      "TOKEN - Classe: id, Lexema: A, Tipo: NULO\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 11 ----------------------------------\n",
      "TOKEN - Classe: se, Lexema: se, Tipo: se\n",
      "TOKEN - Classe: AB_P, Lexema: (, Tipo: NULO\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: OPR, Lexema: >, Tipo: NULO\n",
      "TOKEN - Classe: Num, Lexema: 2, Tipo: inteiro\n",
      "TOKEN - Classe: FC_P, Lexema: ), Tipo: NULO\n",
      "---------------------------------- LINHA 12 ----------------------------------\n",
      "TOKEN - Classe: entao, Lexema: entao, Tipo: entao\n",
      "---------------------------------- LINHA 13 ----------------------------------\n",
      "TOKEN - Classe: se, Lexema: se, Tipo: se\n",
      "TOKEN - Classe: AB_P, Lexema: (, Tipo: NULO\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: OPR, Lexema: <=, Tipo: NULO\n",
      "TOKEN - Classe: Num, Lexema: 4, Tipo: inteiro\n",
      "TOKEN - Classe: FC_P, Lexema: ), Tipo: NULO\n",
      "---------------------------------- LINHA 14 ----------------------------------\n",
      "TOKEN - Classe: entao, Lexema: entao, Tipo: entao\n",
      "---------------------------------- LINHA 15 ----------------------------------\n",
      "TOKEN - Classe: escreva, Lexema: escreva, Tipo: escreva\n",
      "TOKEN - Classe: Lit, Lexema: \"B esta entre 2 e 4\", Tipo: literal\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 16 ----------------------------------\n",
      "TOKEN - Classe: fimse, Lexema: fimse, Tipo: fimse\n",
      "---------------------------------- LINHA 17 ----------------------------------\n",
      "TOKEN - Classe: fimse, Lexema: fimse, Tipo: fimse\n",
      "---------------------------------- LINHA 18 ----------------------------------\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: ATR, Lexema: <-, Tipo: NULO\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: OPA, Lexema: +, Tipo: NULO\n",
      "TOKEN - Classe: Num, Lexema: 1, Tipo: inteiro\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 19 ----------------------------------\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: ATR, Lexema: <-, Tipo: NULO\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: OPA, Lexema: +, Tipo: NULO\n",
      "TOKEN - Classe: Num, Lexema: 2, Tipo: inteiro\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 20 ----------------------------------\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: ATR, Lexema: <-, Tipo: NULO\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: OPA, Lexema: +, Tipo: NULO\n",
      "TOKEN - Classe: Num, Lexema: 3, Tipo: inteiro\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 21 ----------------------------------\n",
      "TOKEN - Classe: id, Lexema: D, Tipo: NULO\n",
      "TOKEN - Classe: ATR, Lexema: <-, Tipo: NULO\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 22 ----------------------------------\n",
      "TOKEN - Classe: id, Lexema: C, Tipo: NULO\n",
      "TOKEN - Classe: ATR, Lexema: <-, Tipo: NULO\n",
      "TOKEN - Classe: Num, Lexema: 5.0, Tipo: real\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 23 ----------------------------------\n",
      "TOKEN - Classe: id, Lexema: E, Tipo: NULO\n",
      "TOKEN - Classe: ATR, Lexema: <-, Tipo: NULO\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: OPA, Lexema: +, Tipo: NULO\n",
      "TOKEN - Classe: Num, Lexema: 2, Tipo: inteiro\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 24 ----------------------------------\n",
      "TOKEN - Classe: escreva, Lexema: escreva, Tipo: escreva\n",
      "TOKEN - Classe: id, Lexema: C, Tipo: NULO\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 25 ----------------------------------\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: ATR, Lexema: <-, Tipo: NULO\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: OPA, Lexema: +, Tipo: NULO\n",
      "TOKEN - Classe: Num, Lexema: 1, Tipo: inteiro\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 26 ----------------------------------\n",
      "TOKEN - Classe: escreva, Lexema: escreva, Tipo: escreva\n",
      "ERRO LÉXICO – Literal incompleto, linha 26, coluna 0\n",
      "---------------------------------- LINHA 27 ----------------------------------\n",
      "TOKEN - Classe: escreva, Lexema: escreva, Tipo: escreva\n",
      "TOKEN - Classe: id, Lexema: D, Tipo: NULO\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 28 ----------------------------------\n",
      "TOKEN - Classe: escreva, Lexema: escreva, Tipo: escreva\n",
      "TOKEN - Classe: Lit, Lexema: \" \", Tipo: literal\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 29 ----------------------------------\n",
      "TOKEN - Classe: escreva, Lexema: escreva, Tipo: escreva\n",
      "TOKEN - Classe: id, Lexema: C, Tipo: NULO\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 30 ----------------------------------\n",
      "TOKEN - Classe: escreva, Lexema: escreva, Tipo: escreva\n",
      "TOKEN - Classe: Lit, Lexema: \" \", Tipo: literal\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 31 ----------------------------------\n",
      "TOKEN - Classe: escreva, Lexema: escreva, Tipo: escreva\n",
      "TOKEN - Classe: id, Lexema: A, Tipo: NULO\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 32 ----------------------------------\n",
      "TOKEN - Classe: fim, Lexema: fim, Tipo: fim\n",
      "---------------------------------- LINHA 33 ----------------------------------\n",
      "TOKEN - Classe: EOF, Lexema: EOF, Tipo: EOF\n"
     ]
    }
   ],
   "source": [
    "tabelaDeEstados = TabelaDeEstados()\n",
    "tabelaDeSimbolos = Tabela_de_Simbolos()\n",
    "# tabelaDeEstados.entradaVazia('     s     ')\n",
    "teste = Scanner()\n",
    "\n",
    "# array = ['a+b;', 'c<-102;' , '{txt;', 'a', '$']\n",
    "# array = ['\"ta\"', \"{a\" ,'$', 'b']\n",
    "# array = ['{teste;' ,'$']\n",
    "# array = ['\"sasa', \"b\" ,'$']\n",
    "# array = [' ','abc','$']\n",
    "# array = ['a+b' , 'c+ç{', '{','$']\n",
    "# array = ['a+b;', 'c<-10e2' ,'$']\n",
    "# array = ['{abc}', 'va','$']\n",
    "# array = ['inteiro B, C','$']\n",
    "# array = ['c<-102; {abc}','$']\n",
    "array = ['teçste','$']\n",
    "# teste.limpa_codigo(teste.codigoFontePalavra, array)\n",
    "teste.scannerMain(tabelaDeEstados, codigoFormatado, tabelaDeSimbolos)\n",
    "\n",
    "# token = Token('id', 'mamaqui', None)\n",
    "# token2 = Token('id', 'token2', None)\n",
    "# tabelaDeSimbolos.inserir_token(token)\n",
    "# tabelaDeSimbolos.inserir_token(token2)\n",
    "# busca = tabelaDeSimbolos.buscar_token(token)\n",
    "# tabelaDeSimbolos.atualizar_token(busca)\n",
    "# tabelaDeEstados.estado_atual = 11\n",
    "# tabelaDeSimbolos.construir_token(tabelaDeEstados, 'mamaqui')\n",
    "# tabelaDeSimbolos.construir_token(tabelaDeEstados, 'mamaqui2')\n",
    "# print('-'*50)\n",
    "# tabelaDeSimbolos.construir_token(tabelaDeEstados, 'mamaqui')\n",
    "# tabelaDeSimbolos.imprimir_tabela()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe:inicio, Lexema:inicio, Tipo:inicio\n",
      "Classe:varinicio, Lexema:varinicio, Tipo:varinicio\n",
      "Classe:varfim, Lexema:varfim, Tipo:varfim\n",
      "Classe:escreva, Lexema:escreva, Tipo:escreva\n",
      "Classe:leia, Lexema:leia, Tipo:leia\n",
      "Classe:se, Lexema:se, Tipo:se\n",
      "Classe:entao, Lexema:entao, Tipo:entao\n",
      "Classe:fimse, Lexema:fimse, Tipo:fimse\n",
      "Classe:fim, Lexema:fim, Tipo:fim\n",
      "Classe:inteiro, Lexema:inteiro, Tipo:inteiro\n",
      "Classe:literal, Lexema:literal, Tipo:literal\n",
      "Classe:real, Lexema:real, Tipo:real\n"
     ]
    }
   ],
   "source": [
    "from Token import Token\n",
    "from tabela_de_estados import TabelaDeEstados\n",
    "\n",
    "class Tabela_de_Simbolos:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.tabela = []\n",
    "\n",
    "        self.tabela.append(Token(classe=\"inicio\",lexema=\"inicio\",tipo=\"inicio\"))\n",
    "        self.tabela.append(Token(classe=\"varinicio\",lexema=\"varinicio\",tipo=\"varinicio\"))\n",
    "        self.tabela.append(Token(classe=\"varfim\", lexema=\"varfim\", tipo=\"varfim\"))\n",
    "        self.tabela.append(Token(classe=\"escreva\",lexema=\"escreva\", tipo=\"escreva\"))\n",
    "        self.tabela.append(Token(classe=\"leia\", lexema=\"leia\",tipo= \"leia\"))\n",
    "        self.tabela.append(Token(classe=\"se\", lexema=\"se\",tipo= \"se\"))\n",
    "        self.tabela.append(Token(classe=\"entao\",lexema= \"entao\",tipo= \"entao\"))\n",
    "        self.tabela.append(Token (classe=\"fimse\",lexema= \"fimse\",tipo= \"fimse\"))\n",
    "        self.tabela.append(Token(classe=\"fim\",lexema= \"fim\", tipo=\"fim\"))\n",
    "        self.tabela.append(Token(classe=\"inteiro\",lexema= \"inteiro\",tipo= \"inteiro\"))\n",
    "        self.tabela.append(Token(classe=\"literal\",lexema= \"literal\",tipo= \"literal\"))\n",
    "        self.tabela.append(Token(classe=\"real\",lexema= \"real\",tipo= \"real\"))\n",
    "\n",
    "\n",
    "    def buscar_token(self, token:Token):\n",
    "            for t in self.tabela:\n",
    "                if(t.lexema == token.lexema):\n",
    "                    return t\n",
    "            return None\n",
    "        \n",
    "\n",
    "    def inserir_token(self, token:Token):\n",
    "            token_encontrado = self.buscar_token(token)\n",
    "            if(token_encontrado is None):\n",
    "                if(token.classe == \"id\"):\n",
    "                    self.tabela.append(token)\n",
    "                return token\n",
    "            else:\n",
    "                return token_encontrado\n",
    "\n",
    "    def atualizar_token(self, token: Token):\n",
    "        if(token.classe == \"id\"):\n",
    "                token_tabela_simbolos = self.buscar_token(token)\n",
    "                if(token_tabela_simbolos):\n",
    "                    self.tabela.remove(token_tabela_simbolos)\n",
    "                    self.tabela.append(token)  \n",
    "\n",
    "    def imprimir_tabela(self):\n",
    "        for t in self.tabela:\n",
    "            print(f\"Classe:{t.classe}, Lexema:{t.lexema}, Tipo:{t.tipo}\")\n",
    "\n",
    "    def construir_token(self, tabela_de_estados: TabelaDeEstados, lexema: str):\n",
    "        classe = tabela_de_estados.retornaClasse()\n",
    "        tipo = tabela_de_estados.retornaTipo()\n",
    "        if classe == 'id':\n",
    "            token = self.buscar_token(Token(classe, lexema, tipo))\n",
    "            if token is None:\n",
    "                token = self.inserir_token(Token(classe, lexema, tipo))\n",
    "\n",
    "            return token\n",
    "        else:\n",
    "            return Token(classe, lexema, tipo)\n",
    "\n",
    "\n",
    "\n",
    "tabelaDeEstados = TabelaDeEstados()\n",
    "tabelaDeSimbolos = Tabela_de_Simbolos()\n",
    "\n",
    "\n",
    "tabelaDeEstados.estado_atual = 28\n",
    "# token = tabelaDeSimbolos.construir_token(tabelaDeEstados, 'fimse')\n",
    "newToken = Token('id', 'dsdsd', 'NULO')\n",
    "# token = tabelaDeSimbolos.construir_token(newToken)\n",
    "token = tabelaDeSimbolos.construir_token(tabelaDeEstados, 'erer')\n",
    "tabela = tabelaDeSimbolos.imprimir_tabela()\n",
    "\n",
    "# print('AAAAAAAAAAAA: ', token)\n",
    "# print('TABELA:: ', tabela)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18ec32658ef92bbbbefc98c3c8471b646fe2ec18f116030ca69b0fc2fc383acb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
