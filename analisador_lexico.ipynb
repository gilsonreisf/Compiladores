{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabela_de_estados import TabelaDeEstados\n",
    "from Tabela_de_Simbolos import Tabela_de_Simbolos\n",
    "from Token import Token\n",
    "\n",
    "class Scanner:\n",
    "  def __init__(self):\n",
    "    self.numero_da_coluna = 0\n",
    "    self.numero_da_linha = 0\n",
    "    self.lexema = ''\n",
    "    self.arrayParaIdentificarColuna = []\n",
    "\n",
    "\n",
    "  def scanner(self, tabelaEstados: TabelaDeEstados, arrayDeCaracteres: str, tabelaDeSimbolos: Tabela_de_Simbolos):\n",
    "    char = arrayDeCaracteres\n",
    "    entrada = tabelaEstados.verificaTipoCaractere(char).strip()\n",
    "    if(entrada == '$'):\n",
    "      if (tabelaEstados.verificarSeEstaEmEstadoFinal()):\n",
    "        newToken = Token(tabelaEstados.retornaClasse(), self.lexema, tabelaEstados.retornaTipo())\n",
    "        return {'mensagem': 'TOKEN', 'token': newToken}\n",
    "      return {'mensagem': 'EOF', 'token': Token(classe='EOF', lexema='EOF',tipo='NULO')}\n",
    "    if (tabelaEstados.verificarSeEntradaPertenceAoAlfabeto(entrada)):\n",
    "      if(tabelaEstados.verificarSeProximoEstadoEValido(entrada)):\n",
    "        self.lexema = self.lexema + char.strip()\n",
    "        return {'mensagem': 'chamar_novamente', 'token': None}\n",
    "      elif(tabelaEstados.verificarSeEFinalDefinitivo(entrada)):\n",
    "          newToken = Token(tabelaEstados.retornaClasse(), self.lexema, tabelaEstados.retornaTipo())\n",
    "          return {'mensagem': 'TOKEN_DIRETO', 'token': newToken}\n",
    "      elif (tabelaEstados.verificarSeEstaEmEstadoFinal()):\n",
    "        newToken = Token(tabelaEstados.retornaClasse(), self.lexema, tabelaEstados.retornaTipo())\n",
    "        return {'mensagem': 'TOKEN', 'token': newToken}\n",
    "      else:\n",
    "        tabelaEstados.lancarErro(self.numero_da_linha, self.numero_da_coluna)\n",
    "        return {'mensagem': None, 'token': None}\n",
    "    elif(tabelaEstados.entradaVazia(char)):\n",
    "      if (tabelaEstados.verificarSeEstaEmEstadoFinal()):\n",
    "        newToken = Token(tabelaEstados.retornaClasse(), self.lexema, tabelaEstados.retornaTipo())\n",
    "        return {'mensagem': 'TOKEN', 'token': newToken}\n",
    "      elif(tabelaEstados.verificarSeComentarioOuLiteral()):\n",
    "        return {'mensagem': 'tratar_literal_comentario', 'token': None}\n",
    "\n",
    "      else:\n",
    "        return {'mensagem': 'chamar_novamente', 'token': None}\n",
    "    else:\n",
    "      self.numero_da_coluna = self.arrayParaIdentificarColuna.index(char) + 1\n",
    "      print('ERRO LÉXICO – Caracter inválido, linha {}, coluna {}'.format(self.numero_da_linha, self.numero_da_coluna))\n",
    "      return {'mensagem': None, 'token': None}\n",
    "\n",
    "\n",
    "\n",
    "  def tratarFinalDaInstrucao(self, tabelaEstados: TabelaDeEstados):\n",
    "    if (tabelaEstados.verificarSeEstaEmEstadoFinal()):\n",
    "      newToken = Token(tabelaEstados.retornaClasse(), self.lexema, tabelaEstados.retornaTipo())\n",
    "      return {'mensagem': 'TOKEN', 'token': newToken}\n",
    "    else:\n",
    "      tabelaEstados.lancarErro(self.numero_da_linha, self.numero_da_coluna)\n",
    "      self.lexema = ''\n",
    "      return {'mensagem': None, 'token': None}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def limpa_codigo(self, codigoFonteFormatado):\n",
    "    codigo_final = []\n",
    "    for line in codigoFonteFormatado:\n",
    "        for caractere in line:\n",
    "            codigo_final.append(caractere)\n",
    "    return codigo_final\n",
    "\n",
    "  def scannerMain(self, tabelaEstados: TabelaDeEstados, codigoFonte, tabelaDeSimbolos: Tabela_de_Simbolos):\n",
    "    for linha in codigoFonte:\n",
    "\n",
    "      arrayDeCaracteres = self.limpa_codigo(linha)\n",
    "      self.arrayParaIdentificarColuna = arrayDeCaracteres.copy()\n",
    "\n",
    "      self.numero_da_linha += 1\n",
    "      coluna = 0\n",
    "      retorno = self.scanner(tabelaEstados, arrayDeCaracteres[0].replace(\" \", \"\"), tabelaDeSimbolos)\n",
    "      arrayDeCaracteres.pop(0)\n",
    "\n",
    "      print('---------------------------------- LINHA {} ----------------------------------'.format(self.numero_da_linha))\n",
    "      if(retorno['mensagem'] == 'EOF'):\n",
    "        print('TOKEN - Classe: EOF, Lexema: EOF, Tipo: EOF')\n",
    "        return # Final do arquivo\n",
    "      while(retorno['mensagem'] != 'EOF' and len(arrayDeCaracteres) != 0):\n",
    "        if(retorno['mensagem'] == 'chamar_novamente'):\n",
    "          coluna += 1\n",
    "          retorno = self.scanner(tabelaEstados, arrayDeCaracteres[0].replace(\" \", \"\"), tabelaDeSimbolos)\n",
    "          if(retorno['mensagem'] != 'TOKEN' and retorno['mensagem'] != 'TOKEN_DIRETO'):\n",
    "            arrayDeCaracteres.pop(0)\n",
    "          continue\n",
    "        elif(retorno['mensagem'] == 'TOKEN'):\n",
    "          tokenTabela = tabelaDeSimbolos.construir_token(tabelaEstados, retorno['token'].lexema)\n",
    "          print('TOKEN - Classe: {}, Lexema: {}, Tipo: {}'.format(tokenTabela.classe, tokenTabela.lexema, tokenTabela.tipo))\n",
    "          tabelaEstados.estado_atual = 0\n",
    "          self.lexema = ''\n",
    "          retorno = self.scanner(tabelaEstados, arrayDeCaracteres[0].replace(\" \", \"\"), tabelaDeSimbolos)\n",
    "          arrayDeCaracteres.pop(0)\n",
    "          continue\n",
    "        elif(retorno['mensagem'] == 'TOKEN_DIRETO'):\n",
    "          tokenTabela = tabelaDeSimbolos.construir_token(tabelaEstados, retorno['token'].lexema)\n",
    "          print('TOKEN - Classe: {}, Lexema: {}, Tipo: {}'.format(tokenTabela.classe, tokenTabela.lexema, tokenTabela.tipo))\n",
    "\n",
    "          tabelaEstados.estado_atual = 0\n",
    "          arrayDeCaracteres.pop(0)\n",
    "          self.lexema = ''\n",
    "          \n",
    "          retorno = self.scanner(tabelaEstados, arrayDeCaracteres[0].replace(\" \", \"\"), tabelaDeSimbolos)\n",
    "          continue\n",
    "        elif(retorno['mensagem']  == None): #Espaço vazio\n",
    "          ultimoTokenAntesDoErro = self.tratarFinalDaInstrucao(tabelaEstados)\n",
    "          if(ultimoTokenAntesDoErro['mensagem'] == 'TOKEN'):\n",
    "            tokenTabela = tabelaDeSimbolos.construir_token(tabelaEstados, ultimoTokenAntesDoErro['token'].lexema)\n",
    "            print('TOKEN - Classe: {}, Lexema: {}, Tipo: {}'.format(tokenTabela.classe, tokenTabela.lexema, tokenTabela.tipo))\n",
    "          \n",
    "          tabelaEstados.estado_atual = 0\n",
    "          self.lexema = ''\n",
    "          retorno['mensagem'] = 'chamar_novamente'\n",
    "          coluna += 1\n",
    "          continue\n",
    "\n",
    "        elif(retorno['mensagem']  == 'tratar_literal_comentario'):\n",
    "          self.lexema =  self.lexema + ' '\n",
    "          retorno['mensagem'] = 'chamar_novamente'\n",
    "          continue\n",
    "\n",
    "\n",
    "      ultimoTokenDaLinha = self.tratarFinalDaInstrucao(tabelaEstados)\n",
    "      if(ultimoTokenDaLinha['mensagem'] == 'TOKEN'):\n",
    "        tokenTabela = tabelaDeSimbolos.construir_token(tabelaEstados, ultimoTokenDaLinha['token'].lexema)\n",
    "        print('TOKEN - Classe: {}, Lexema: {}, Tipo: {}'.format(tokenTabela.classe, tokenTabela.lexema, tokenTabela.tipo))\n",
    "        tabelaEstados.estado_atual = 0\n",
    "        self.lexema = ''\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A;', 'B;', 'A;', '$\\n', '$']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivo = open(\"teste.txt\", \"r+\", encoding=\"utf-8\")\n",
    "codigoFonte = arquivo.readlines()\n",
    "\n",
    "def limpa_codigo(codigoFonte):\n",
    "  novo_codigo = []\n",
    "  ultimo_elemento = codigoFonte[-1]\n",
    "  for i in codigoFonte:\n",
    "    if(i.strip() == ultimo_elemento.strip()):\n",
    "      i = i + '\\n'\n",
    "    nova_string = bytes(i, \"utf-8\").decode(\"unicode_escape\")\n",
    "    novo_codigo.append(nova_string[:][:-1])\n",
    "  novo_codigo.append('$')\n",
    "  return novo_codigo\n",
    "  \n",
    "codigoFormatado = limpa_codigo(codigoFonte)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "codigoFormatado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------- LINHA 1 ----------------------------------\n",
      "TOKEN ENCONTRADO:  None\n",
      "TOKEN - Classe: id, Lexema: A, Tipo: NULO\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 2 ----------------------------------\n",
      "TOKEN ENCONTRADO:  None\n",
      "TOKEN - Classe: id, Lexema: B, Tipo: NULO\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 3 ----------------------------------\n",
      "TOKEN ENCONTRADO:  Classe: id, Lexema: A, Tipo: NULO\n",
      "TOKEN - Classe: id, Lexema: A, Tipo: NULO\n",
      "TOKEN - Classe: PT_V, Lexema: ;, Tipo: NULO\n",
      "---------------------------------- LINHA 4 ----------------------------------\n",
      "TOKEN - Classe: EOF, Lexema: EOF, Tipo: EOF\n",
      "Classe:inicio, Lexema:inicio, Tipo:inicio\n",
      "Classe:varinicio, Lexema:varinicio, Tipo:varinicio\n",
      "Classe:varfim, Lexema:varfim, Tipo:varfim\n",
      "Classe:escreva, Lexema:escreva, Tipo:escreva\n",
      "Classe:leia, Lexema:leia, Tipo:leia\n",
      "Classe:se, Lexema:se, Tipo:se\n",
      "Classe:entao, Lexema:entao, Tipo:entao\n",
      "Classe:fimse, Lexema:fimse, Tipo:fimse\n",
      "Classe:fim, Lexema:fim, Tipo:fim\n",
      "Classe:inteiro, Lexema:inteiro, Tipo:inteiro\n",
      "Classe:literal, Lexema:literal, Tipo:literal\n",
      "Classe:real, Lexema:real, Tipo:real\n",
      "Classe:id, Lexema:B, Tipo:NULO\n",
      "Classe:id, Lexema:A, Tipo:NULO\n"
     ]
    }
   ],
   "source": [
    "tabelaDeEstados = TabelaDeEstados()\n",
    "tabelaDeSimbolos = Tabela_de_Simbolos()\n",
    "# tabelaDeEstados.entradaVazia('     s     ')\n",
    "teste = Scanner()\n",
    "\n",
    "# array = ['a+b;', 'c<-102;' , '{txt;', 'a', '$']\n",
    "# array = ['\"ta\"', \"{a\" ,'$', 'b']\n",
    "# array = ['{teste;' ,'$']\n",
    "# array = ['\"sasa', \"b\" ,'$']\n",
    "# array = [' ','abc','$']\n",
    "# array = ['a+b' , 'c+ç{', '{','$']\n",
    "# array = ['a+b;', 'c<-10e2' ,'$']\n",
    "# array = ['{abc}', 'va','$']\n",
    "# array = ['inteiro B, C','$']\n",
    "# array = ['c<-102; {abc}','$']\n",
    "array = ['teçste','$']\n",
    "# teste.limpa_codigo(teste.codigoFontePalavra, array)\n",
    "teste.scannerMain(tabelaDeEstados, codigoFormatado, tabelaDeSimbolos)\n",
    "\n",
    "# token = Token('id', 'mamaqui', None)\n",
    "# token2 = Token('id', 'token2', None)\n",
    "# tabelaDeSimbolos.inserir_token(token)\n",
    "# tabelaDeSimbolos.inserir_token(token2)\n",
    "# busca = tabelaDeSimbolos.buscar_token(token)\n",
    "# tabelaDeSimbolos.atualizar_token(busca)\n",
    "# tabelaDeEstados.estado_atual = 11\n",
    "# tabelaDeSimbolos.construir_token(tabelaDeEstados, 'mamaqui')\n",
    "# tabelaDeSimbolos.construir_token(tabelaDeEstados, 'mamaqui2')\n",
    "# print('-'*50)\n",
    "# tabelaDeSimbolos.construir_token(tabelaDeEstados, 'mamaqui')\n",
    "tabelaDeSimbolos.imprimir_tabela()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe:inicio, Lexema:inicio, Tipo:inicio\n",
      "Classe:varinicio, Lexema:varinicio, Tipo:varinicio\n",
      "Classe:varfim, Lexema:varfim, Tipo:varfim\n",
      "Classe:escreva, Lexema:escreva, Tipo:escreva\n",
      "Classe:leia, Lexema:leia, Tipo:leia\n",
      "Classe:se, Lexema:se, Tipo:se\n",
      "Classe:entao, Lexema:entao, Tipo:entao\n",
      "Classe:fimse, Lexema:fimse, Tipo:fimse\n",
      "Classe:fim, Lexema:fim, Tipo:fim\n",
      "Classe:inteiro, Lexema:inteiro, Tipo:inteiro\n",
      "Classe:literal, Lexema:literal, Tipo:literal\n",
      "Classe:real, Lexema:real, Tipo:real\n"
     ]
    }
   ],
   "source": [
    "from Token import Token\n",
    "from tabela_de_estados import TabelaDeEstados\n",
    "\n",
    "class Tabela_de_Simbolos:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.tabela = []\n",
    "\n",
    "        self.tabela.append(Token(classe=\"inicio\",lexema=\"inicio\",tipo=\"inicio\"))\n",
    "        self.tabela.append(Token(classe=\"varinicio\",lexema=\"varinicio\",tipo=\"varinicio\"))\n",
    "        self.tabela.append(Token(classe=\"varfim\", lexema=\"varfim\", tipo=\"varfim\"))\n",
    "        self.tabela.append(Token(classe=\"escreva\",lexema=\"escreva\", tipo=\"escreva\"))\n",
    "        self.tabela.append(Token(classe=\"leia\", lexema=\"leia\",tipo= \"leia\"))\n",
    "        self.tabela.append(Token(classe=\"se\", lexema=\"se\",tipo= \"se\"))\n",
    "        self.tabela.append(Token(classe=\"entao\",lexema= \"entao\",tipo= \"entao\"))\n",
    "        self.tabela.append(Token (classe=\"fimse\",lexema= \"fimse\",tipo= \"fimse\"))\n",
    "        self.tabela.append(Token(classe=\"fim\",lexema= \"fim\", tipo=\"fim\"))\n",
    "        self.tabela.append(Token(classe=\"inteiro\",lexema= \"inteiro\",tipo= \"inteiro\"))\n",
    "        self.tabela.append(Token(classe=\"literal\",lexema= \"literal\",tipo= \"literal\"))\n",
    "        self.tabela.append(Token(classe=\"real\",lexema= \"real\",tipo= \"real\"))\n",
    "\n",
    "\n",
    "    def buscar_token(self, token:Token):\n",
    "            for t in self.tabela:\n",
    "                if(t.lexema == token.lexema):\n",
    "                    return t\n",
    "            return None\n",
    "        \n",
    "\n",
    "    def inserir_token(self, token:Token):\n",
    "            token_encontrado = self.buscar_token(token)\n",
    "            if(token_encontrado is None):\n",
    "                if(token.classe == \"id\"):\n",
    "                    self.tabela.append(token)\n",
    "                return token\n",
    "            else:\n",
    "                return token_encontrado\n",
    "\n",
    "    def atualizar_token(self, token: Token):\n",
    "        if(token.classe == \"id\"):\n",
    "                token_tabela_simbolos = self.buscar_token(token)\n",
    "                if(token_tabela_simbolos):\n",
    "                    self.tabela.remove(token_tabela_simbolos)\n",
    "                    self.tabela.append(token)  \n",
    "\n",
    "    def imprimir_tabela(self):\n",
    "            for t in self.tabela:\n",
    "                print(f\"Classe:{t.classe}, Lexema:{t.lexema}, Tipo:{t.tipo}\")\n",
    "\n",
    "    def construir_token(self, tabela_de_estados: TabelaDeEstados, lexema: str):\n",
    "        classe = tabela_de_estados.retornaClasse()\n",
    "        tipo = tabela_de_estados.retornaTipo()\n",
    "        if classe == 'id':\n",
    "            token = self.buscar_token(Token(classe, lexema, tipo))\n",
    "            if token is None:\n",
    "                token = self.inserir_token(Token(classe, lexema, tipo))\n",
    "\n",
    "            return token\n",
    "        else:\n",
    "            return Token(classe, lexema, tipo)\n",
    "\n",
    "\n",
    "\n",
    "tabelaDeEstados = TabelaDeEstados()\n",
    "tabelaDeSimbolos = Tabela_de_Simbolos()\n",
    "\n",
    "\n",
    "tabelaDeEstados.estado_atual = 28\n",
    "# token = tabelaDeSimbolos.construir_token(tabelaDeEstados, 'fimse')\n",
    "newToken = Token('id', 'dsdsd', 'NULO')\n",
    "# token = tabelaDeSimbolos.construir_token(newToken)\n",
    "token = tabelaDeSimbolos.construir_token(tabelaDeEstados, 'erer')\n",
    "tabela = tabelaDeSimbolos.imprimir_tabela()\n",
    "\n",
    "# print('AAAAAAAAAAAA: ', token)\n",
    "# print('TABELA:: ', tabela)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18ec32658ef92bbbbefc98c3c8471b646fe2ec18f116030ca69b0fc2fc383acb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
